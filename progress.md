* [x] **LeNet-5** (1998) – *Gradient-Based Learning Applied to Document Recognition*
* [x] **AlexNet** (2012) – *ImageNet Classification with Deep CNNs*
* [ ] **VGG** (2014) – *Very Deep Convolutional Networks for Large-Scale Image Recognition*
* [ ] **GoogLeNet / Inception** (2015) – *Going Deeper with Convolutions*
* [ ] **ResNet** (2016) – *Deep Residual Learning for Image Recognition*
* [ ] **ResNeXt** (2017) – *Aggregated Residual Transformations for Deep Neural Networks*
* [ ] **DenseNet** (2017) – *Densely Connected Convolutional Networks*
* [ ] **R-CNN Family** (2014+) – *Rich feature hierarchies for accurate object detection*
* [ ] **SSD (Single Shot Multibox Detector)** (2016) – *SSD: Single Shot MultiBox Detector*

* [ ] **word2vec** (2013) – *Efficient Estimation of Word Representations in Vector Space*
* [ ] **GloVe** (2014) – *GloVe: Global Vectors for Word Representation*
* [ ] **BERT** (2018) – *Pre-training of Deep Bidirectional Transformers*

* [ ] **The Transformer** (2017) – *Attention Is All You Need*
* [ ] **Vision Transformer (ViT)** (2020) – *An Image is Worth 16x16 Words*

* [ ] **LSTM** (1997) – *Long Short-Term Memory*
* [ ] **GRU** (2014) – *Learning Phrase Representations using RNN Encoder-Decoder*

* [ ] **GAN** (2014) – *Generative Adversarial Nets*
* [ ] **DCGAN** (2015) – *Unsupervised Representation Learning with DCGANs*
